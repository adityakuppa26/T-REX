{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af020557-9f7a-4aa1-8191-c71f19610d3f",
      "metadata": {
        "id": "af020557-9f7a-4aa1-8191-c71f19610d3f"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback\n",
        "from stable_baselines3 import PPO\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "import torch\n",
        "from torch.nn import LogSoftmax\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29553fa8-34ee-447a-8c14-5f64fed8ce0b",
      "metadata": {
        "id": "29553fa8-34ee-447a-8c14-5f64fed8ce0b"
      },
      "outputs": [],
      "source": [
        "env = gym.make('HalfCheetah-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d87305a6-b453-4d84-b3d2-e42561254637",
      "metadata": {
        "id": "d87305a6-b453-4d84-b3d2-e42561254637",
        "outputId": "3dc98b99-0272-4e55-f7d3-88354c3d7929"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/aditya/envs/rl38/lib/python3.8/site-packages/gymnasium/envs/registration.py:513: DeprecationWarning: \u001b[33mWARN: The environment HalfCheetah-v2 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.deprecation(\n",
            "/home/aditya/envs/rl38/lib/python3.8/site-packages/gymnasium/envs/mujoco/mujoco_env.py:211: DeprecationWarning: \u001b[33mWARN: This version of the mujoco environments depends on the mujoco-py bindings, which are no longer maintained and may stop working. Please upgrade to the v4 versions of the environments (which depend on the mujoco python bindings instead), unless you are trying to precisely replicate previous works).\u001b[0m\n",
            "  logger.deprecation(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | -404     |\n",
            "| time/              |          |\n",
            "|    fps             | 1609     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | -423        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1113        |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 3           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010157889 |\n",
            "|    clip_fraction        | 0.126       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -8.51       |\n",
            "|    explained_variance   | -0.0467     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 18.6        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0216     |\n",
            "|    std                  | 0.998       |\n",
            "|    value_loss           | 47.9        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | -399        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1016        |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 6           |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008050652 |\n",
            "|    clip_fraction        | 0.0586      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -8.49       |\n",
            "|    explained_variance   | 0.0184      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 13.2        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0166     |\n",
            "|    std                  | 0.994       |\n",
            "|    value_loss           | 60          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | -398        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 930         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 8           |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008915361 |\n",
            "|    clip_fraction        | 0.0762      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -8.46       |\n",
            "|    explained_variance   | 0.338       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 14.1        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0193     |\n",
            "|    std                  | 0.99        |\n",
            "|    value_loss           | 27.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | -403        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 913         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 11          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009462359 |\n",
            "|    clip_fraction        | 0.0896      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -8.45       |\n",
            "|    explained_variance   | 0.199       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 14.2        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0177     |\n",
            "|    std                  | 0.988       |\n",
            "|    value_loss           | 43.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | -387        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 889         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 13          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009723419 |\n",
            "|    clip_fraction        | 0.0941      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -8.41       |\n",
            "|    explained_variance   | 0.304       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 11.2        |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0222     |\n",
            "|    std                  | 0.979       |\n",
            "|    value_loss           | 20.6        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | -383        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 874         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 16          |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008517953 |\n",
            "|    clip_fraction        | 0.0775      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -8.38       |\n",
            "|    explained_variance   | 0.48        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 12.2        |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0179     |\n",
            "|    std                  | 0.978       |\n",
            "|    value_loss           | 30.9        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | -381        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 867         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 18          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009215267 |\n",
            "|    clip_fraction        | 0.0789      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -8.37       |\n",
            "|    explained_variance   | 0.233       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.31        |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.022      |\n",
            "|    std                  | 0.974       |\n",
            "|    value_loss           | 19.9        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | -374        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 864         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 21          |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008217597 |\n",
            "|    clip_fraction        | 0.0682      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -8.35       |\n",
            "|    explained_variance   | 0.32        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 22.6        |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.0174     |\n",
            "|    std                  | 0.972       |\n",
            "|    value_loss           | 42.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | -369        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 865         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 23          |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011955826 |\n",
            "|    clip_fraction        | 0.144       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -8.3        |\n",
            "|    explained_variance   | 0.294       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.67        |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0284     |\n",
            "|    std                  | 0.959       |\n",
            "|    value_loss           | 14.7        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | -361       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 864        |\n",
            "|    iterations           | 11         |\n",
            "|    time_elapsed         | 26         |\n",
            "|    total_timesteps      | 22528      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00966807 |\n",
            "|    clip_fraction        | 0.096      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -8.26      |\n",
            "|    explained_variance   | 0.355      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 13.2       |\n",
            "|    n_updates            | 100        |\n",
            "|    policy_gradient_loss | -0.0262    |\n",
            "|    std                  | 0.957      |\n",
            "|    value_loss           | 24.1       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | -359       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 864        |\n",
            "|    iterations           | 12         |\n",
            "|    time_elapsed         | 28         |\n",
            "|    total_timesteps      | 24576      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01013328 |\n",
            "|    clip_fraction        | 0.123      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -8.22      |\n",
            "|    explained_variance   | 0.581      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 4.44       |\n",
            "|    n_updates            | 110        |\n",
            "|    policy_gradient_loss | -0.0289    |\n",
            "|    std                  | 0.948      |\n",
            "|    value_loss           | 14         |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | -355       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 861        |\n",
            "|    iterations           | 13         |\n",
            "|    time_elapsed         | 30         |\n",
            "|    total_timesteps      | 26624      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01185861 |\n",
            "|    clip_fraction        | 0.138      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -8.16      |\n",
            "|    explained_variance   | 0.589      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 10.3       |\n",
            "|    n_updates            | 120        |\n",
            "|    policy_gradient_loss | -0.0304    |\n",
            "|    std                  | 0.941      |\n",
            "|    value_loss           | 15.5       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | -353        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 861         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 33          |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009053466 |\n",
            "|    clip_fraction        | 0.092       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -8.13       |\n",
            "|    explained_variance   | 0.41        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 13.1        |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0235     |\n",
            "|    std                  | 0.936       |\n",
            "|    value_loss           | 30.6        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | -348        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 861         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 35          |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010544301 |\n",
            "|    clip_fraction        | 0.115       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -8.1        |\n",
            "|    explained_variance   | 0.517       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 14.2        |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.0292     |\n",
            "|    std                  | 0.933       |\n",
            "|    value_loss           | 25          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | -340        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 860         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 38          |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008190084 |\n",
            "|    clip_fraction        | 0.0803      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -8.08       |\n",
            "|    explained_variance   | 0.591       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 14.1        |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.023      |\n",
            "|    std                  | 0.93        |\n",
            "|    value_loss           | 25          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | -339        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 858         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 40          |\n",
            "|    total_timesteps      | 34816       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012372613 |\n",
            "|    clip_fraction        | 0.14        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -8.06       |\n",
            "|    explained_variance   | 0.528       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.42        |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.0332     |\n",
            "|    std                  | 0.925       |\n",
            "|    value_loss           | 23.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | -340        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 858         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 42          |\n",
            "|    total_timesteps      | 36864       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010578012 |\n",
            "|    clip_fraction        | 0.12        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -8.04       |\n",
            "|    explained_variance   | 0.762       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 29.2        |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.0294     |\n",
            "|    std                  | 0.924       |\n",
            "|    value_loss           | 48.3        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | -337         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 857          |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 45           |\n",
            "|    total_timesteps      | 38912        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0130459275 |\n",
            "|    clip_fraction        | 0.155        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -8.03        |\n",
            "|    explained_variance   | 0.282        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 13.7         |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -0.0371      |\n",
            "|    std                  | 0.921        |\n",
            "|    value_loss           | 24           |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | -333        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 857         |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 47          |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015185877 |\n",
            "|    clip_fraction        | 0.166       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.99       |\n",
            "|    explained_variance   | 0.438       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.59        |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.0394     |\n",
            "|    std                  | 0.913       |\n",
            "|    value_loss           | 12.9        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | -329        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 857         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 50          |\n",
            "|    total_timesteps      | 43008       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009821392 |\n",
            "|    clip_fraction        | 0.114       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.98       |\n",
            "|    explained_variance   | 0.31        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 13.7        |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.0274     |\n",
            "|    std                  | 0.915       |\n",
            "|    value_loss           | 34.9        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | -325        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 857         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 52          |\n",
            "|    total_timesteps      | 45056       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012062855 |\n",
            "|    clip_fraction        | 0.128       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.96       |\n",
            "|    explained_variance   | 0.395       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 11.9        |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.0312     |\n",
            "|    std                  | 0.91        |\n",
            "|    value_loss           | 20.6        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 1e+03        |\n",
            "|    ep_rew_mean          | -321         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 858          |\n",
            "|    iterations           | 23           |\n",
            "|    time_elapsed         | 54           |\n",
            "|    total_timesteps      | 47104        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0121143935 |\n",
            "|    clip_fraction        | 0.134        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -7.95        |\n",
            "|    explained_variance   | 0.482        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 10.7         |\n",
            "|    n_updates            | 220          |\n",
            "|    policy_gradient_loss | -0.0351      |\n",
            "|    std                  | 0.908        |\n",
            "|    value_loss           | 17.3         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | -319        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 857         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 57          |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016317122 |\n",
            "|    clip_fraction        | 0.195       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.92       |\n",
            "|    explained_variance   | 0.596       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.59        |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.0401     |\n",
            "|    std                  | 0.903       |\n",
            "|    value_loss           | 11.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | -318        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 855         |\n",
            "|    iterations           | 25          |\n",
            "|    time_elapsed         | 59          |\n",
            "|    total_timesteps      | 51200       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013126705 |\n",
            "|    clip_fraction        | 0.146       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.89       |\n",
            "|    explained_variance   | 0.632       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.7         |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.0348     |\n",
            "|    std                  | 0.9         |\n",
            "|    value_loss           | 15.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | -316        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 852         |\n",
            "|    iterations           | 26          |\n",
            "|    time_elapsed         | 62          |\n",
            "|    total_timesteps      | 53248       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012667527 |\n",
            "|    clip_fraction        | 0.141       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.85       |\n",
            "|    explained_variance   | 0.485       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 10.7        |\n",
            "|    n_updates            | 250         |\n",
            "|    policy_gradient_loss | -0.0342     |\n",
            "|    std                  | 0.892       |\n",
            "|    value_loss           | 21.6        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | -315        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 846         |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 65          |\n",
            "|    total_timesteps      | 55296       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010302205 |\n",
            "|    clip_fraction        | 0.116       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.82       |\n",
            "|    explained_variance   | 0.433       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 15.5        |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | -0.0281     |\n",
            "|    std                  | 0.891       |\n",
            "|    value_loss           | 24.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | -311        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 842         |\n",
            "|    iterations           | 28          |\n",
            "|    time_elapsed         | 68          |\n",
            "|    total_timesteps      | 57344       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013926787 |\n",
            "|    clip_fraction        | 0.143       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.78       |\n",
            "|    explained_variance   | 0.504       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.82        |\n",
            "|    n_updates            | 270         |\n",
            "|    policy_gradient_loss | -0.0352     |\n",
            "|    std                  | 0.88        |\n",
            "|    value_loss           | 15.7        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | -308       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 842        |\n",
            "|    iterations           | 29         |\n",
            "|    time_elapsed         | 70         |\n",
            "|    total_timesteps      | 59392      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01565145 |\n",
            "|    clip_fraction        | 0.181      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -7.75      |\n",
            "|    explained_variance   | 0.456      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 4.98       |\n",
            "|    n_updates            | 280        |\n",
            "|    policy_gradient_loss | -0.0423    |\n",
            "|    std                  | 0.88       |\n",
            "|    value_loss           | 11.3       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | -307        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 841         |\n",
            "|    iterations           | 30          |\n",
            "|    time_elapsed         | 72          |\n",
            "|    total_timesteps      | 61440       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011279044 |\n",
            "|    clip_fraction        | 0.129       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.74       |\n",
            "|    explained_variance   | 0.573       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.55        |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | -0.032      |\n",
            "|    std                  | 0.877       |\n",
            "|    value_loss           | 21          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | -304        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 838         |\n",
            "|    iterations           | 31          |\n",
            "|    time_elapsed         | 75          |\n",
            "|    total_timesteps      | 63488       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014268982 |\n",
            "|    clip_fraction        | 0.151       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.71       |\n",
            "|    explained_variance   | 0.535       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.07        |\n",
            "|    n_updates            | 300         |\n",
            "|    policy_gradient_loss | -0.0366     |\n",
            "|    std                  | 0.874       |\n",
            "|    value_loss           | 15.9        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1e+03       |\n",
            "|    ep_rew_mean          | -302        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 839         |\n",
            "|    iterations           | 32          |\n",
            "|    time_elapsed         | 78          |\n",
            "|    total_timesteps      | 65536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011610903 |\n",
            "|    clip_fraction        | 0.125       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -7.68       |\n",
            "|    explained_variance   | 0.507       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.94        |\n",
            "|    n_updates            | 310         |\n",
            "|    policy_gradient_loss | -0.0337     |\n",
            "|    std                  | 0.867       |\n",
            "|    value_loss           | 20.5        |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x7f8a71dd07f0>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# define env and policy model\n",
        "env = gym.make('HalfCheetah-v2')\n",
        "checkpoint_callback = CheckpointCallback(\n",
        "  save_freq=4000,\n",
        "  save_path=\"./logs/\",\n",
        "  name_prefix=\"rl_model\",\n",
        "  save_replay_buffer=True,\n",
        "  save_vecnormalize=True,\n",
        ")\n",
        "\n",
        "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
        "model.learn(total_timesteps=64000, callback=checkpoint_callback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31756b97-f6d5-458b-af8d-c1f7cfea4d4e",
      "metadata": {
        "id": "31756b97-f6d5-458b-af8d-c1f7cfea4d4e"
      },
      "outputs": [],
      "source": [
        "class Dataset():\n",
        "    def __init__(self, env, dir=\"./logs\", size=1000):\n",
        "        self.dir = dir\n",
        "        self.size = size\n",
        "        self.env = env\n",
        "        self.trajs = []\n",
        "\n",
        "    def generate_trajectory(self, model, min_len=100):\n",
        "        state = env.reset()[0]\n",
        "        obs, actions, rewards = [state], [], []\n",
        "        for i in range(1000):\n",
        "            action, _ = model.predict(state)\n",
        "            state, reward, done, _, _ = env.step(action)\n",
        "            env.render()\n",
        "            obs.append(state)\n",
        "            actions.append(action)\n",
        "            rewards.append(reward)\n",
        "\n",
        "            if done:\n",
        "                if len(obs) < min_len:\n",
        "                    obs.pop()\n",
        "                    state = env.reset()[0]\n",
        "                    obs.append(state)\n",
        "                else:\n",
        "                    obs.pop()\n",
        "                    break\n",
        "        return (np.stack(obs, axis=0), np.stack(actions, axis=0), rewards)\n",
        "\n",
        "    def generate_dataset(self, models):\n",
        "        for model in models:\n",
        "            traj = self.generate_trajectory(model)\n",
        "            self.trajs.append(traj)\n",
        "        obs, actions, rewards = zip(*self.trajs)\n",
        "        self.trajs = (np.concatenate(obs, axis=0),np.concatenate(actions,axis=0),np.concatenate(rewards,axis=0))\n",
        "\n",
        "    def generate_ranked_pairs(self, segment_length=50):\n",
        "        ranked_dataset = []\n",
        "        obs, actions, rewards = self.trajs\n",
        "\n",
        "        for i in range(self.size):\n",
        "            t1_start = random.randint(0, len(obs)-segment_length-1)\n",
        "            t2_start = random.randint(0, len(obs)-segment_length-1)\n",
        "            t1_end = t1_start + segment_length\n",
        "            t2_end = t2_start + segment_length\n",
        "            t1_return = sum(rewards[t1_start:t1_end])\n",
        "            t2_return = sum(rewards[t2_start:t2_end])\n",
        "            d = (obs[t1_start:t1_end], obs[t2_start:t2_end], 0 if t1_return > t2_return else 1)\n",
        "            ranked_dataset.append(d)\n",
        "\n",
        "        return ranked_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad3d6e76-e52d-483c-a8a7-917f60e073dd",
      "metadata": {
        "id": "ad3d6e76-e52d-483c-a8a7-917f60e073dd",
        "outputId": "b3a8d0d0-0853-4a33-e5ed-b65ef77cd6f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ],
      "source": [
        "# create ranked pairs of trajectories\n",
        "def create_ranked_pairs(env=env):\n",
        "    dataset=Dataset(env=env)\n",
        "    models = []\n",
        "    for model_path in os.listdir(\"./logs\"):\n",
        "        model_path = \"./logs/\" + model_path[:-4]\n",
        "        model = PPO.load(model_path, env=env)\n",
        "        models.append(model)\n",
        "    dataset.generate_dataset(models=models)\n",
        "\n",
        "    return dataset.generate_ranked_pairs()\n",
        "\n",
        "ranked_pair_dataset = create_ranked_pairs(env=env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "612cae64-d480-41d0-a9d5-66ecc654b605",
      "metadata": {
        "id": "612cae64-d480-41d0-a9d5-66ecc654b605"
      },
      "outputs": [],
      "source": [
        "class RewardModel(nn.Module):\n",
        "    def __init__(self, in_dims=17):\n",
        "        super().__init__()\n",
        "        self.in_dims = in_dims\n",
        "        self.loss_fn = LogSoftmax(dim=1)\n",
        "\n",
        "\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(self.in_dims, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "    def train(self, x, optimizer, epochs=20):\n",
        "        loss = 0\n",
        "        for e in range(1,epochs+1):\n",
        "            b = 0\n",
        "            bloss = []\n",
        "            for t1, t2, y in x:\n",
        "                t1_return_predcited = torch.sum(self.forward(torch.from_numpy(t1).to(torch.float32)))\n",
        "                t2_return_predcited = torch.sum(self.forward(torch.from_numpy(t2).to(torch.float32)))\n",
        "                t_stack = torch.stack((t1_return_predcited,t2_return_predcited), dim=0).reshape((1,2)) # [1,2] for sgd\n",
        "                loss += -self.loss_fn(t_stack)[0][y]\n",
        "                b += 1\n",
        "                if b%64 == 0:\n",
        "                    loss = loss/64\n",
        "                    bloss.append(loss)\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    loss = 0\n",
        "            print(\"loss after {} epoch: {}\".format(e, sum(bloss)/len(bloss)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1534266f-2c12-4377-83a7-69f6a4780a2a",
      "metadata": {
        "id": "1534266f-2c12-4377-83a7-69f6a4780a2a"
      },
      "outputs": [],
      "source": [
        "model = RewardModel()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e899bb1e-e6ad-4f46-9dec-6a06c09aeda7",
      "metadata": {
        "id": "e899bb1e-e6ad-4f46-9dec-6a06c09aeda7",
        "outputId": "697d743b-2c3e-4ab4-b0e1-a7fc39d857db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss after 1 epoch: 0.6357890963554382\n",
            "loss after 2 epoch: 0.4068799614906311\n",
            "loss after 3 epoch: 0.34277665615081787\n",
            "loss after 4 epoch: 0.2707604169845581\n",
            "loss after 5 epoch: 0.26000961661338806\n",
            "loss after 6 epoch: 0.22391971945762634\n",
            "loss after 7 epoch: 0.19832585752010345\n",
            "loss after 8 epoch: 0.17795917391777039\n",
            "loss after 9 epoch: 0.15314528346061707\n",
            "loss after 10 epoch: 0.13230834901332855\n",
            "loss after 11 epoch: 0.129897341132164\n",
            "loss after 12 epoch: 0.12240181118249893\n",
            "loss after 13 epoch: 0.1351267397403717\n",
            "loss after 14 epoch: 0.17856083810329437\n",
            "loss after 15 epoch: 0.1812516152858734\n",
            "loss after 16 epoch: 0.16456995904445648\n",
            "loss after 17 epoch: 0.13276347517967224\n",
            "loss after 18 epoch: 0.12200073897838593\n",
            "loss after 19 epoch: 0.12759491801261902\n",
            "loss after 20 epoch: 0.13036884367465973\n"
          ]
        }
      ],
      "source": [
        "model.train(ranked_pair_dataset, optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e60caae-7851-44f4-babc-295264b76047",
      "metadata": {
        "id": "5e60caae-7851-44f4-babc-295264b76047",
        "outputId": "d88b3380-8f87-4659-ccd3-1218e272b8fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "0.804\n"
          ]
        }
      ],
      "source": [
        "test_ranked_pairs = create_ranked_pairs(env=env)\n",
        "def eval(x):\n",
        "    acc = []\n",
        "    for t1, t2, y in x:\n",
        "        ret_t1 = sum(model(torch.from_numpy(t1).to(torch.float32)))\n",
        "        ret_t2 = sum(model(torch.from_numpy(t2).to(torch.float32)))\n",
        "        if ret_t1 > ret_t2:\n",
        "            xx = y == 0\n",
        "        else:\n",
        "            xx = y == 1\n",
        "        if xx:\n",
        "            acc.append(1)\n",
        "        else:\n",
        "            acc.append(0)\n",
        "    return sum(acc)/len(acc)\n",
        "print(eval(test_ranked_pairs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9f0e7d3-f82a-447b-89e0-42062970579a",
      "metadata": {
        "id": "a9f0e7d3-f82a-447b-89e0-42062970579a",
        "outputId": "3372e9d0-20bb-49db-acc6-61f2350a115c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([11.0971], grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe7eac07-2fff-46d1-a040-06f9311d6c97",
      "metadata": {
        "id": "fe7eac07-2fff-46d1-a040-06f9311d6c97"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7ed9549-e082-4ba4-9f8a-fa42d38b8028",
      "metadata": {
        "id": "d7ed9549-e082-4ba4-9f8a-fa42d38b8028"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dac47a1-6e34-40ba-940d-d37e3cdd8944",
      "metadata": {
        "id": "1dac47a1-6e34-40ba-940d-d37e3cdd8944"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd918ec5-3846-45a5-85e6-02a26f6e3bd4",
      "metadata": {
        "id": "bd918ec5-3846-45a5-85e6-02a26f6e3bd4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5c14373-a1eb-4be6-b2d6-50c15f0ecb1a",
      "metadata": {
        "id": "a5c14373-a1eb-4be6-b2d6-50c15f0ecb1a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecb22c6a-1360-4821-a3a0-27495980b3f9",
      "metadata": {
        "id": "ecb22c6a-1360-4821-a3a0-27495980b3f9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}